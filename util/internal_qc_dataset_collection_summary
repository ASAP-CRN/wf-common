#!/bin/bash

set -eEuo pipefail

usage() {
cat << EOF

  Track datasets in internal QC by getting their ASAP raw buckets, size, and sample breakdown in GCP.
  Note:
  - Raw bucket sizes include files that are used for development
  - Storage size used for this project is much larger since unreleased data is stored in there as well and cross-team cohort data
  - Sample breakdown is ongoing as more data modalities are being added
  - Sample count can change as our Data Curators collaborate with CRN Teams to define this

  Usage: $0 [OPTIONS]

  OPTIONS
    -h  Display this message and exit
    -s  Grab no. of samples only

EOF
}

SAMPLES_ONLY=false

while getopts ":hs" OPTION; do
  case ${OPTION} in
    h) usage; exit 1;;
    s) SAMPLES_ONLY=true;;
  esac
done


date_str=$(date +"%Y-%m-%d")
output_file="internal_qc_dataset_collection_summary.$date_str.tsv"
echo -e "team\tgcp_raw_bucket\tgcp_raw_bucket_size\tsample_count" > "$output_file"

all_raw_buckets=$(gcloud storage buckets list \
    --format="value(name)" \
    --filter="name:asap-raw-team*")

RAW_BUCKETS=""
while IFS= read -r bucket; do
    if [ -n "$bucket" ]; then
        if gcloud storage buckets describe "gs://$bucket" \
            --format="value(labels)" 2>/dev/null | grep -q "internal-qc-data"; then
            RAW_BUCKETS="${RAW_BUCKETS}${bucket}"$'\n'
        fi
    fi
done <<< "$all_raw_buckets"
RAW_BUCKETS=$(echo "$RAW_BUCKETS" | sed "/^$/d")

echo "Got "$(echo "$RAW_BUCKETS" | wc -l | tr -d '[:space:]')" individual datasets in internal QC from GCP"

while IFS= read -r bucket; do
    echo "Processing bucket: $bucket"

    team=$(echo "$bucket" | sed "s/^asap-raw-team-//" | cut -d'-' -f1)
    gcp_raw_bucket=$(echo "gs://$bucket")

    echo "Trying to get # of samples"
    sample_count="NA"
    # First try: metadata/release/SAMPLE.csv
    if gcloud storage ls "$gcp_raw_bucket/metadata/release/SAMPLE.csv" &>/dev/null; then
        echo "  Found metadata/release/SAMPLE.csv"
        sample_count=$(gcloud storage cat "$gcp_raw_bucket/metadata/release/SAMPLE.csv" | tail -n +2 | wc -l)
    else
    # Second try: search metadata/ for any SAMPLE.csv
        echo "  metadata/release/SAMPLE.csv not found, searching metadata folder for SAMPLE.csv..."
        sample_csv=$(gcloud storage ls -r "$gcp_raw_bucket/metadata" 2>/dev/null | grep "SAMPLE.csv" | head -n 1 || true)

        if [ -n "$sample_csv" ]; then
            echo "  Found SAMPLE.csv at: $sample_csv"
            sample_count=$(gcloud storage cat "$sample_csv" | tail -n +2 | wc -l)
        else
            echo "  No SAMPLE.csv found in metadata/ path"
        fi
    fi

    if "${SAMPLES_ONLY}"; then
        gcp_raw_bucket_size="NA"
    else
        echo "Getting GCP raw bucket size"
        gcp_raw_bucket_size=$(gcloud storage du -s "$gcp_raw_bucket" | grep -oE '^[0-9]+')
    fi

    echo -e "${team}\t${gcp_raw_bucket}\t${gcp_raw_bucket_size}\t${sample_count}" >> "$output_file"
done <<< "$RAW_BUCKETS"

if "${SAMPLES_ONLY}"; then
    echo "Calculating the sample breakdown"
    awk -F'\t' '
    NR==1 {
        for (i=1; i<=NF; i++) {
            if ($i == "sample_count") sample_col = i
            if ($i == "gcp_raw_bucket") bucket_col = i
            if ($i == "team") team_col = i
        }
        next
    }

    NR>1 {
        count = $sample_col
        bucket = $bucket_col
        asap_team = $team_col

        if (count == "NA") {
            na_buckets[bucket] = 1
            next
        }

        total_samples += count
        team_samples[asap_team] += count

        # Grouping logic
        category = ""
        if (bucket ~ /sc-rnaseq/ || bucket ~ /sn-rnaseq/) {
            category = "sc_sn"
            grp["sc_sn"] += count
        } else if (bucket ~ /bulk-rnaseq/) {
            category = "bulk"
            grp["bulk"] += count
        } else if (bucket ~ /spatial/) {
            category = "spatial"
            grp["spatial"] += count
        } else if (bucket ~ /ms-p/) {
            category = "ms_p"
            grp["ms_p"] += count
        } else if (bucket ~ /parsebio/) {
            category = "parsebio"
            grp["parsebio"] += count
        } else if (bucket ~ /metagenome/) {
            category = "metagenomics"
            grp["metagenomics"] += count
        } else {
            category = "other"
            grp["other"] += count
            other_buckets[bucket] = 1  # track bucket name
        }

        team_category[asap_team, category] += count
        team_list[asap_team] = 1
        category_list[category] = 1
    }

    END {
        print "=== SAMPLE COUNT SUMMARY ==="
        print "Total samples:", total_samples
        print ""

        print "=== BREAKDOWN ==="
        printf "sc/sn RNAseq: %d\n", grp["sc_sn"]
        printf "bulk RNAseq:  %d\n", grp["bulk"]
        printf "spatial:      %d\n", grp["spatial"]
        printf "proteomics:   %d\n", grp["ms_p"]
        printf "parsebio:     %d\n", grp["parsebio"]
        printf "metagenomics: %d\n", grp["metagenomics"]
        printf "other:        %d\n", grp["other"]
        print ""

        if (length(other_buckets) > 0) {
            print "=== BUCKETS IN '\''OTHER'\'' CATEGORY ==="
            for (b in other_buckets) {
                print b
            }
            print ""
        }
        
        print "=== BREAKDOWN BY TEAM ==="
        for (team in team_samples) {
            team_name = toupper(substr(team, 1, 1)) substr(team, 2)
            printf "%d samples belong to Team %s\n", team_samples[team], team_name
        }
        print ""
    
        print "=== BREAKDOWN BY TEAM AND DATA TYPE ==="
        for (team in team_list) {
            team_name = toupper(substr(team, 1, 1)) substr(team, 2)
            printf "Team %s:\n", team_name
            
            if (team_category[team, "sc_sn"] > 0)
                printf "  sc/sn RNAseq: %d\n", team_category[team, "sc_sn"]
            if (team_category[team, "bulk"] > 0)
                printf "  bulk RNAseq:  %d\n", team_category[team, "bulk"]
            if (team_category[team, "spatial"] > 0)
                printf "  spatial:      %d\n", team_category[team, "spatial"]
            if (team_category[team, "ms_p"] > 0)
                printf "  proteomics:   %d\n", team_category[team, "ms_p"]
            if (team_category[team, "parsebio"] > 0)
                printf "  parsebio:     %d\n", team_category[team, "parsebio"]
            if (team_category[team, "metagenomics"] > 0)
                printf "  metagenomics: %d\n", team_category[team, "metagenomics"]
            if (team_category[team, "other"] > 0)
                printf "  other:        %d\n", team_category[team, "other"]
            print ""
        }
        
        if (length(na_buckets) > 0) {
            print ""
            print "=== BUCKETS WITH NO SAMPLE.CSV FOUND ==="
            for (b in na_buckets) {
                print b
            }
        }
    }' "$output_file"
else
    echo "Calculating the total size of raw buckets"
    awk -F'\t' '
    NR==1 {
        for(i=1;i<=NF;i++){
            if($i=="gcp_raw_bucket_size") raw_col=i
        }
        next
    }

    NR>1 {
        if (raw_col > 0) total_raw += $raw_col
    }

    END {
        tb_raw  = total_raw  / (1024^4)

        print "=== BUCKET SIZE SUMMARY ==="
        printf "Total raw size (TB):   %.1f\n", tb_raw
    }' "$output_file"
fi

echo "Saved results to [$(pwd)/$output_file]"
